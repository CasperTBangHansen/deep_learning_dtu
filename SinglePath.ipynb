{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "97632eb2",
   "metadata": {},
   "source": [
    "# Deep learning single path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84c6a75c",
   "metadata": {},
   "source": [
    "## Data setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c181da0a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\" \n",
    "os.environ[\"CUDA_LAUNCH_BLOCKING\"]=\"1\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]= f\"{1}\"\n",
    "\n",
    "from singlePathModel import Dict, to_cuda, is_cuda, create_sub_blocks, SuperArchitectureNoLinear, SuperArchitecture\n",
    "import logging\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.datasets import MNIST, CIFAR100, CIFAR10\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "from math import floor\n",
    "import time\n",
    "from sklearn.metrics import accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Logging\n",
    "filename = \"SinglePathCIFAR100\"\n",
    "logging.basicConfig(filename = f\"logs/{filename}\", filemode = 'w', format='%(asctime)s - %(message)s', level=logging.DEBUG)\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1d53b8e",
   "metadata": {},
   "source": [
    "## Cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "74afb534",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "if is_cuda():\n",
    "    print(\"cuda\")\n",
    "    device = torch.device(\"cuda\")\n",
    "    print(torch.cuda.current_device())\n",
    "else:\n",
    "    print(\"cpu\")\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cdd9beb",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a701c774",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "load_mnist = False\n",
    "load_cifar = False\n",
    "load_cifar100 = True\n",
    "\n",
    "if load_mnist:\n",
    "    transform = transforms.Compose([transforms.ToTensor()])\n",
    "    train_data_set = MNIST(\"./temp/\", train=True, download=True, transform=transform)\n",
    "    test_data_set = MNIST(\"./temp/\", train=False, download=True, transform=transform)\n",
    "\n",
    "if load_cifar:\n",
    "    transform = transforms.Compose(\n",
    "        [transforms.ToTensor(),\n",
    "         transforms.Normalize((0.5, 0.5, 0.5),(0.5, 0.5, 0.5))\n",
    "        ]\n",
    "    )\n",
    "    train_data_set = CIFAR10(\"./temp/\", train=True, download=True, transform=transform)\n",
    "    test_data_set = CIFAR10(\"./temp/\", train=False, download=True, transform=transform)\n",
    "if load_cifar100:\n",
    "    transform = transforms.Compose(\n",
    "        [transforms.ToTensor(),\n",
    "         transforms.Normalize((0.5, 0.5, 0.5),(0.5, 0.5, 0.5))\n",
    "        ]\n",
    "    )\n",
    "    train_data_set = CIFAR100(\"./temp/\", train=True, download=True, transform=transform)\n",
    "    test_data_set = CIFAR100(\"./temp/\", train=False, download=True, transform=transform)\n",
    "trainloader = DataLoader(train_data_set, batch_size=16, shuffle=True, num_workers=2)\n",
    "testloader = DataLoader(test_data_set, batch_size=16, shuffle=True, num_workers=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f36fd09e",
   "metadata": {},
   "source": [
    "## Single path model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ee4afa1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparam = {\n",
    "    'MNIST' : {\n",
    "        'num_epochs' : 100,\n",
    "        'lr' : 0.001,\n",
    "        'momentum': 0.8\n",
    "    },\n",
    "    'CIFAR' : {\n",
    "        'num_epochs' : 50,\n",
    "        'lr' : 0.01,\n",
    "        'momentum': 0.8\n",
    "    }\n",
    "}\n",
    "if load_mnist:\n",
    "    chosen_hyp = hyperparam['MNIST']\n",
    "if load_cifar or load_cifar100:\n",
    "    chosen_hyp = hyperparam['CIFAR']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3b76b65d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data size\n",
    "x, y = next(iter(trainloader))\n",
    "batch_size, channels, img_x, img_y = x.shape\n",
    "data_points = len(trainloader)*batch_size\n",
    "n_classes = len(set(train_data_set.targets))\n",
    "# Setup the different layers\n",
    "\n",
    "# Linear layers\n",
    "first_linear_params = [\n",
    "    Dict(in_features=img_x*img_y, out_features=256),\n",
    "    Dict(in_features=256, out_features=64),\n",
    "]\n",
    "\n",
    "# Conv layers\n",
    "default_param = dict(expand_ratio_list=[3,5,7,9], kernel_size_list=[3,5,7,9])\n",
    "dims = [1*channels, 4*channels, 8*channels, 16*channels, 32*channels, 64*channels, 126*channels, 250*channels]\n",
    "middle_conv_params = []\n",
    "for dim1, dim2 in zip(dims[:-1], dims[1:]):\n",
    "    middle_conv_params.append(Dict(in_channels=dim1, out_channels=dim2, **default_param, blocks=1, stride=1))\n",
    "    middle_conv_params.append(Dict(in_channels=dim2, out_channels=dim2, **default_param, blocks=1, stride=1))\n",
    "\n",
    "# Last conv\n",
    "last_conv_param = Dict(in_channels=dims[-1], out_channels=dims[-1], kernel_size=1, stride=1)\n",
    "\n",
    "# Output linear layer\n",
    "last_linear_params = [\n",
    "    dict(in_features=dims[-1], out_features=n_classes)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2bb79196",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SuperArchitectureNoLinear(\n",
      "  (middle): Sequential(\n",
      "    (0): SuperConvBlock(\n",
      "      (module): Sequential(\n",
      "        (0): Sequential(\n",
      "          (0): SuperConv2d()\n",
      "          (1): BatchNorm2d(27, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6()\n",
      "        )\n",
      "        (1): Sequential(\n",
      "          (0): SuperConv2d()\n",
      "          (1): BatchNorm2d(27, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6()\n",
      "        )\n",
      "        (2): Sequential(\n",
      "          (0): Conv2d(27, 12, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(12, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (shortcut): Sequential(\n",
      "        (0): Conv2d(3, 12, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(12, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): SuperConvBlock(\n",
      "      (module): Sequential(\n",
      "        (0): Sequential(\n",
      "          (0): SuperConv2d()\n",
      "          (1): BatchNorm2d(108, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6()\n",
      "        )\n",
      "        (1): Sequential(\n",
      "          (0): SuperConv2d()\n",
      "          (1): BatchNorm2d(108, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6()\n",
      "        )\n",
      "        (2): Sequential(\n",
      "          (0): Conv2d(108, 12, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(12, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (shortcut): Sequential()\n",
      "    )\n",
      "    (2): SuperConvBlock(\n",
      "      (module): Sequential(\n",
      "        (0): Sequential(\n",
      "          (0): SuperConv2d()\n",
      "          (1): BatchNorm2d(108, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6()\n",
      "        )\n",
      "        (1): Sequential(\n",
      "          (0): SuperConv2d()\n",
      "          (1): BatchNorm2d(108, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6()\n",
      "        )\n",
      "        (2): Sequential(\n",
      "          (0): Conv2d(108, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (shortcut): Sequential(\n",
      "        (0): Conv2d(12, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (3): SuperConvBlock(\n",
      "      (module): Sequential(\n",
      "        (0): Sequential(\n",
      "          (0): SuperConv2d()\n",
      "          (1): BatchNorm2d(216, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6()\n",
      "        )\n",
      "        (1): Sequential(\n",
      "          (0): SuperConv2d()\n",
      "          (1): BatchNorm2d(216, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6()\n",
      "        )\n",
      "        (2): Sequential(\n",
      "          (0): Conv2d(216, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (shortcut): Sequential()\n",
      "    )\n",
      "    (4): SuperConvBlock(\n",
      "      (module): Sequential(\n",
      "        (0): Sequential(\n",
      "          (0): SuperConv2d()\n",
      "          (1): BatchNorm2d(216, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6()\n",
      "        )\n",
      "        (1): Sequential(\n",
      "          (0): SuperConv2d()\n",
      "          (1): BatchNorm2d(216, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6()\n",
      "        )\n",
      "        (2): Sequential(\n",
      "          (0): Conv2d(216, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (shortcut): Sequential(\n",
      "        (0): Conv2d(24, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (5): SuperConvBlock(\n",
      "      (module): Sequential(\n",
      "        (0): Sequential(\n",
      "          (0): SuperConv2d()\n",
      "          (1): BatchNorm2d(432, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6()\n",
      "        )\n",
      "        (1): Sequential(\n",
      "          (0): SuperConv2d()\n",
      "          (1): BatchNorm2d(432, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6()\n",
      "        )\n",
      "        (2): Sequential(\n",
      "          (0): Conv2d(432, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (shortcut): Sequential()\n",
      "    )\n",
      "    (6): SuperConvBlock(\n",
      "      (module): Sequential(\n",
      "        (0): Sequential(\n",
      "          (0): SuperConv2d()\n",
      "          (1): BatchNorm2d(432, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6()\n",
      "        )\n",
      "        (1): Sequential(\n",
      "          (0): SuperConv2d()\n",
      "          (1): BatchNorm2d(432, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6()\n",
      "        )\n",
      "        (2): Sequential(\n",
      "          (0): Conv2d(432, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (shortcut): Sequential(\n",
      "        (0): Conv2d(48, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (7): SuperConvBlock(\n",
      "      (module): Sequential(\n",
      "        (0): Sequential(\n",
      "          (0): SuperConv2d()\n",
      "          (1): BatchNorm2d(864, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6()\n",
      "        )\n",
      "        (1): Sequential(\n",
      "          (0): SuperConv2d()\n",
      "          (1): BatchNorm2d(864, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6()\n",
      "        )\n",
      "        (2): Sequential(\n",
      "          (0): Conv2d(864, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (shortcut): Sequential()\n",
      "    )\n",
      "    (8): SuperConvBlock(\n",
      "      (module): Sequential(\n",
      "        (0): Sequential(\n",
      "          (0): SuperConv2d()\n",
      "          (1): BatchNorm2d(864, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6()\n",
      "        )\n",
      "        (1): Sequential(\n",
      "          (0): SuperConv2d()\n",
      "          (1): BatchNorm2d(864, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6()\n",
      "        )\n",
      "        (2): Sequential(\n",
      "          (0): Conv2d(864, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (shortcut): Sequential(\n",
      "        (0): Conv2d(96, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (9): SuperConvBlock(\n",
      "      (module): Sequential(\n",
      "        (0): Sequential(\n",
      "          (0): SuperConv2d()\n",
      "          (1): BatchNorm2d(1728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6()\n",
      "        )\n",
      "        (1): Sequential(\n",
      "          (0): SuperConv2d()\n",
      "          (1): BatchNorm2d(1728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6()\n",
      "        )\n",
      "        (2): Sequential(\n",
      "          (0): Conv2d(1728, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (shortcut): Sequential()\n",
      "    )\n",
      "    (10): SuperConvBlock(\n",
      "      (module): Sequential(\n",
      "        (0): Sequential(\n",
      "          (0): SuperConv2d()\n",
      "          (1): BatchNorm2d(1728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6()\n",
      "        )\n",
      "        (1): Sequential(\n",
      "          (0): SuperConv2d()\n",
      "          (1): BatchNorm2d(1728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6()\n",
      "        )\n",
      "        (2): Sequential(\n",
      "          (0): Conv2d(1728, 378, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(378, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (shortcut): Sequential(\n",
      "        (0): Conv2d(192, 378, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(378, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (11): SuperConvBlock(\n",
      "      (module): Sequential(\n",
      "        (0): Sequential(\n",
      "          (0): SuperConv2d()\n",
      "          (1): BatchNorm2d(3402, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6()\n",
      "        )\n",
      "        (1): Sequential(\n",
      "          (0): SuperConv2d()\n",
      "          (1): BatchNorm2d(3402, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6()\n",
      "        )\n",
      "        (2): Sequential(\n",
      "          (0): Conv2d(3402, 378, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(378, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (shortcut): Sequential()\n",
      "    )\n",
      "    (12): SuperConvBlock(\n",
      "      (module): Sequential(\n",
      "        (0): Sequential(\n",
      "          (0): SuperConv2d()\n",
      "          (1): BatchNorm2d(3402, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6()\n",
      "        )\n",
      "        (1): Sequential(\n",
      "          (0): SuperConv2d()\n",
      "          (1): BatchNorm2d(3402, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6()\n",
      "        )\n",
      "        (2): Sequential(\n",
      "          (0): Conv2d(3402, 750, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(750, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (shortcut): Sequential(\n",
      "        (0): Conv2d(378, 750, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(750, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (13): SuperConvBlock(\n",
      "      (module): Sequential(\n",
      "        (0): Sequential(\n",
      "          (0): SuperConv2d()\n",
      "          (1): BatchNorm2d(6750, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6()\n",
      "        )\n",
      "        (1): Sequential(\n",
      "          (0): SuperConv2d()\n",
      "          (1): BatchNorm2d(6750, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6()\n",
      "        )\n",
      "        (2): Sequential(\n",
      "          (0): Conv2d(6750, 750, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(750, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (shortcut): Sequential()\n",
      "    )\n",
      "  )\n",
      "  (end): Sequential(\n",
      "    (0): Sequential(\n",
      "      (0): Conv2d(750, 750, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(750, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU6()\n",
      "    )\n",
      "    (1): Sequential(\n",
      "      (0): AdaptiveAvgPool2d(output_size=1)\n",
      "    )\n",
      "  )\n",
      "  (out): Sequential(\n",
      "    (0): Linear(in_features=750, out_features=100, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "net = SuperArchitectureNoLinear(\n",
    "    #first_linear_params=first_linear_params,\n",
    "    middle_conv_params=middle_conv_params,\n",
    "    last_conv_param=last_conv_param,\n",
    "    last_linear_params=last_linear_params\n",
    ").cuda()\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3d8be6d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_thresholds(net, val_images, val_labels, threshold_optimizer, criterion):\n",
    "    \"\"\" Trains the threshold parameter\"\"\"\n",
    "    # Zero_grad\n",
    "    threshold_optimizer.zero_grad()\n",
    "\n",
    "    # Predict and eval\n",
    "    val_logits = net(val_images)\n",
    "    val_loss = criterion(val_logits, val_labels)\n",
    "\n",
    "    # Optimize\n",
    "    val_loss.backward()\n",
    "    threshold_optimizer.step()\n",
    "    return val_logits, val_loss\n",
    "\n",
    "def train_weights(net, train_images, train_targets, weight_optimizer, criterion):\n",
    "    \"\"\" Trains the weights\"\"\"\n",
    "    # Zero_grad\n",
    "    weight_optimizer.zero_grad()\n",
    "    \n",
    "    # Predict and eval\n",
    "    train_logits = net(train_images)\n",
    "    train_loss = criterion(train_logits, train_targets)\n",
    "\n",
    "    # Optimize\n",
    "    train_loss.backward()\n",
    "    weight_optimizer.step()\n",
    "    return train_logits, train_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffc2adc7",
   "metadata": {},
   "source": [
    "# Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f1b5e70e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup\n",
    "# Init\n",
    "losses = []\n",
    "test_acc = []\n",
    "train_acc = []\n",
    "\n",
    "# Init network\n",
    "net = SuperArchitectureNoLinear(\n",
    "    #first_linear_params=first_linear_params,\n",
    "    middle_conv_params=middle_conv_params,\n",
    "    last_conv_param=last_conv_param,\n",
    "    last_linear_params=last_linear_params\n",
    ").cuda()\n",
    "\n",
    "# Eval model doing training\n",
    "eval_model = True\n",
    "\n",
    "# Save time\n",
    "train_time = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2ab5589a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "weight_optimizer = torch.optim.SGD(\n",
    "    params=net.weights(),\n",
    "    lr=chosen_hyp['lr'],\n",
    "    momentum=chosen_hyp['momentum']\n",
    ")\n",
    "\n",
    "threshold_optimizer = torch.optim.Adam(\n",
    "    params=net.thresholds(),\n",
    "    lr=0.01,\n",
    "    weight_decay=0.001\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7dd4e54",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started training\n",
      "Epoch  1 : Train Loss 787.227905, Train acc 0.163420, Test acc 0.163000, Epoch train time 21.82 min\n",
      "Epoch  2 : Train Loss 665.342834, Train acc 0.270660, Test acc 0.263100, Epoch train time 21.78 min\n",
      "Epoch  3 : Train Loss 580.044617, Train acc 0.359820, Test acc 0.343300, Epoch train time 21.57 min\n",
      "Epoch  4 : Train Loss 513.720642, Train acc 0.430680, Test acc 0.398700, Epoch train time 22.62 min\n",
      "Epoch  5 : Train Loss 458.821045, Train acc 0.484660, Test acc 0.455100, Epoch train time 21.78 min\n",
      "Epoch  6 : Train Loss 420.137726, Train acc 0.532360, Test acc 0.481600, Epoch train time 21.70 min\n",
      "Epoch  7 : Train Loss 383.627319, Train acc 0.560960, Test acc 0.504800, Epoch train time 21.70 min\n",
      "Epoch  8 : Train Loss 352.930389, Train acc 0.600640, Test acc 0.531400, Epoch train time 21.72 min\n",
      "Epoch  9 : Train Loss 327.077301, Train acc 0.635160, Test acc 0.561300, Epoch train time 22.00 min\n",
      "Epoch 10 : Train Loss 305.315216, Train acc 0.657720, Test acc 0.579600, Epoch train time 21.45 min\n",
      "Epoch 11 : Train Loss 286.293945, Train acc 0.611160, Test acc 0.537300, Epoch train time 21.34 min\n",
      "Epoch 12 : Train Loss 268.312286, Train acc 0.711020, Test acc 0.598700, Epoch train time 22.05 min\n",
      "Epoch 13 : Train Loss 251.267990, Train acc 0.726580, Test acc 0.600200, Epoch train time 21.90 min\n",
      "Epoch 14 : Train Loss 234.493530, Train acc 0.744320, Test acc 0.611000, Epoch train time 21.78 min\n",
      "Epoch 15 : Train Loss 219.034988, Train acc 0.770300, Test acc 0.629700, Epoch train time 21.77 min\n",
      "Epoch 16 : Train Loss 205.594193, Train acc 0.791360, Test acc 0.634300, Epoch train time 21.90 min\n",
      "Epoch 17 : Train Loss 194.761032, Train acc 0.808900, Test acc 0.640400, Epoch train time 22.02 min\n",
      "Epoch 18 : Train Loss 181.535172, Train acc 0.819820, Test acc 0.646800, Epoch train time 21.92 min\n",
      "Epoch 19 : Train Loss 167.735229, Train acc 0.838420, Test acc 0.651600, Epoch train time 22.13 min\n"
     ]
    }
   ],
   "source": [
    "print(\"Started training\")\n",
    "logging.debug(\"Started training\")\n",
    "for epoch in range(chosen_hyp['num_epochs']):\n",
    "    start_time = time.perf_counter()\n",
    "    # Forward -> Backprob -> Update params\n",
    "    \n",
    "    ## Train\n",
    "    cur_loss = 0\n",
    "    net.train()\n",
    "    for data in trainloader:\n",
    "        # Get data\n",
    "        x, y = data\n",
    "        x_train, y_train = x[::2], y[::2]\n",
    "        x_val, y_val = x[1::2], y[1::2]\n",
    "        # Optimizer and batch\n",
    "        train_logits, train_loss = train_weights(net, x_train.cuda(), y_train.cuda(), weight_optimizer, criterion)\n",
    "        val_logits, val_loss = train_thresholds(net, x_val.cuda(), y_val.cuda(), threshold_optimizer, criterion)\n",
    "        \n",
    "        cur_loss += train_loss\n",
    "    \n",
    "    end_time = time.perf_counter()\n",
    "    train_time.append(end_time - start_time)\n",
    "    # Save losses\n",
    "    losses.append(cur_loss / batch_size)\n",
    "    \n",
    "    if eval_model:\n",
    "        ### Evaluate training\n",
    "        net.eval()\n",
    "        print(\"You can break now!\", end='\\r')\n",
    "        logging.debug(\"You can break now!\")\n",
    "        train_preds, train_targs = [], []\n",
    "        for data in trainloader:\n",
    "            x_train, y_train = data\n",
    "            output = net(x_train.cuda())\n",
    "\n",
    "            preds = torch.max(output, 1)[1]\n",
    "\n",
    "            train_targs += list(y_train.numpy())\n",
    "            train_preds += list(preds.data.cpu().numpy())\n",
    "\n",
    "        ### Evaluate validation\n",
    "        test_preds, test_targs = [], []\n",
    "        for data in testloader:\n",
    "            x_test, y_test = data\n",
    "            output = net(x_test.cuda())\n",
    "            preds = torch.max(output, 1)[1]\n",
    "            test_targs += list(y_test.numpy())\n",
    "            test_preds += list(preds.data.cpu().numpy())\n",
    "\n",
    "\n",
    "        train_acc_cur = accuracy_score(train_targs, train_preds)\n",
    "        test_acc_cur = accuracy_score(test_targs, test_preds)\n",
    "\n",
    "        train_acc.append(train_acc_cur)\n",
    "        test_acc.append(test_acc_cur)\n",
    "        \n",
    "        logging.debug(\"Do not break!\")\n",
    "        print(\"Do not break!\", end='\\r')\n",
    "\n",
    "        if epoch % 1 == 0:\n",
    "            string = \"Epoch %2i : Train Loss %f, Train acc %f, Test acc %f, Epoch train time %.2f min\" % (\n",
    "                    epoch+1, losses[-1], train_acc_cur, test_acc_cur, train_time[-1]/60)\n",
    "            logging.debug(string)\n",
    "            print(string)\n",
    "    else:\n",
    "        string = \"Epoch %2i, Epoch train time %.2f min\" % (epoch+1, train_time[-1]/60)\n",
    "        logging.debug(string)\n",
    "        print(string)\n",
    "\n",
    "logging.debug(f\"Total time: {sum(train_time)/(60*60)} hours\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caeceee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(net, f\"models/{filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a28736ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "net.eval()\n",
    "print(f'Training accuracy: {train_acc[-1]*100:.2f}%\\nTest accuracy: {test_acc[-1]*100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41d14ef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "if eval_model:\n",
    "    epoch = list(range(len(train_acc)))\n",
    "    plt.figure()\n",
    "    plt.plot(epoch, train_acc, 'r', epoch, test_acc, 'b')\n",
    "    plt.legend(['Train Accucary','Test Accuracy'])\n",
    "    plt.xlabel('Updates')\n",
    "    plt.ylabel('Acc')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dda55d51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21486434"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum([par.numel() for par in net.parameters()])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
