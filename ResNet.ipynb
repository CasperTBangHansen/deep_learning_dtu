{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "97632eb2",
   "metadata": {},
   "source": [
    "# Deep learning baseline project"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84c6a75c",
   "metadata": {},
   "source": [
    "## Data setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c181da0a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from resnet import ResNet18, ResNet50\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.datasets import MNIST, CIFAR100, CIFAR10\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch\n",
    "from typing import Tuple\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import logging\n",
    "import time\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=f'{0}'\n",
    "\n",
    "\n",
    "# Logging\n",
    "filename = \"ResNet50CIFAR100\"\n",
    "logging.basicConfig(filename = f\"logs/{filename}\", filemode = 'w', format='%(asctime)s - %(message)s', level=logging.DEBUG)\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1d53b8e",
   "metadata": {},
   "source": [
    "## Cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3d157031",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed Dec 22 19:30:46 2021       \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| NVIDIA-SMI 495.44       Driver Version: 495.44       CUDA Version: 11.5     |\r\n",
      "|-------------------------------+----------------------+----------------------+\r\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n",
      "|                               |                      |               MIG M. |\r\n",
      "|===============================+======================+======================|\r\n",
      "|   0  NVIDIA A100-PCI...  On   | 00000000:37:00.0 Off |                    0 |\r\n",
      "| N/A   39C    P0    33W / 250W |      0MiB / 40536MiB |      0%      Default |\r\n",
      "|                               |                      |             Disabled |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "|   1  NVIDIA A100-PCI...  On   | 00000000:86:00.0 Off |                    0 |\r\n",
      "| N/A   72C    P0    78W / 250W |   9526MiB / 40536MiB |      0%      Default |\r\n",
      "|                               |                      |             Disabled |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "                                                                               \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| Processes:                                                                  |\r\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\r\n",
      "|        ID   ID                                                   Usage      |\r\n",
      "|=============================================================================|\r\n",
      "|    1   N/A  N/A      1323      C   ...olution/.venv/bin/python3     9523MiB |\r\n",
      "+-----------------------------------------------------------------------------+\r\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "74afb534",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    print(\"cuda\")\n",
    "    device = torch.device(\"cuda\")\n",
    "    print(torch.cuda.current_device())\n",
    "else:\n",
    "    print(\"cpu\")\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cdd9beb",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bcdd5e96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz to ./temp/cifar-100-python.tar.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1.8%IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "4.8%IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "7.9%IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "10.9%IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "13.9%IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "16.9%IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "23.5%IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "29.6%IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "35.8%IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "42.3%IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "45.9%IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "49.2%IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "52.8%IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "55.6%IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "59.1%IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "63.1%IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "67.6%IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "73.9%IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "79.8%IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "86.8%IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "93.2%IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "99.8%IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "load_mnist = False\n",
    "load_cifar = False\n",
    "load_cifar100 = True\n",
    "\n",
    "if load_mnist:\n",
    "    transform = transforms.Compose([transforms.ToTensor()])\n",
    "    train_data_set = MNIST(\"./temp/\", train=True, download=True, transform=transform)\n",
    "    test_data_set = MNIST(\"./temp/\", train=False, download=True, transform=transform)\n",
    "\n",
    "if load_cifar:\n",
    "    transform = transforms.Compose(\n",
    "        [transforms.ToTensor(),\n",
    "         transforms.Normalize((0.5, 0.5, 0.5),(0.5, 0.5, 0.5))\n",
    "        ]\n",
    "    )\n",
    "    train_data_set = CIFAR10(\"./temp/\", train=True, download=True, transform=transform)\n",
    "    test_data_set = CIFAR10(\"./temp/\", train=False, download=True, transform=transform)\n",
    "if load_cifar100:\n",
    "    transform = transforms.Compose(\n",
    "        [transforms.ToTensor(),\n",
    "         transforms.Normalize((0.5, 0.5, 0.5),(0.5, 0.5, 0.5))\n",
    "        ]\n",
    "    )\n",
    "    train_data_set = CIFAR100(\"./temp/\", train=True, download=True, transform=transform)\n",
    "    test_data_set = CIFAR100(\"./temp/\", train=False, download=True, transform=transform)\n",
    "trainloader = DataLoader(train_data_set, batch_size=16, shuffle=True, num_workers=2)\n",
    "testloader = DataLoader(test_data_set, batch_size=16, shuffle=True, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4dafd993",
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = next(iter(trainloader))\n",
    "batch_size, channels, img_x, img_y = x.shape\n",
    "data_points = len(trainloader)*batch_size\n",
    "n_classes = len(set(train_data_set.targets))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f36fd09e",
   "metadata": {},
   "source": [
    "## ResNet model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8cb68d84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet(\n",
      "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU()\n",
      "      (shortcut): Sequential(\n",
      "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU()\n",
      "      (shortcut): Sequential()\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU()\n",
      "      (shortcut): Sequential()\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU()\n",
      "      (shortcut): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU()\n",
      "      (shortcut): Sequential()\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU()\n",
      "      (shortcut): Sequential()\n",
      "    )\n",
      "    (3): Bottleneck(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU()\n",
      "      (shortcut): Sequential()\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU()\n",
      "      (shortcut): Sequential(\n",
      "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU()\n",
      "      (shortcut): Sequential()\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU()\n",
      "      (shortcut): Sequential()\n",
      "    )\n",
      "    (3): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU()\n",
      "      (shortcut): Sequential()\n",
      "    )\n",
      "    (4): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU()\n",
      "      (shortcut): Sequential()\n",
      "    )\n",
      "    (5): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU()\n",
      "      (shortcut): Sequential()\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU()\n",
      "      (shortcut): Sequential(\n",
      "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU()\n",
      "      (shortcut): Sequential()\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU()\n",
      "      (shortcut): Sequential()\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): Linear(in_features=2048, out_features=100, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "net = ResNet50(\n",
    "    channels = channels,\n",
    "    num_classes = n_classes\n",
    ").cuda()\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94948c9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  1 : Train Loss 795.305542, Train acc 0.156920, Test acc 0.149000, Epoch train time 1.79 min\n",
      "Epoch  2 : Train Loss 676.465515, Train acc 0.261200, Test acc 0.229900, Epoch train time 1.78 min\n",
      "Epoch  3 : Train Loss 601.816833, Train acc 0.348080, Test acc 0.283800, Epoch train time 1.90 min\n",
      "Epoch  4 : Train Loss 535.959534, Train acc 0.420540, Test acc 0.320200, Epoch train time 1.75 min\n",
      "Epoch  5 : Train Loss 476.758087, Train acc 0.487120, Test acc 0.338200, Epoch train time 1.69 min\n",
      "Epoch  6 : Train Loss 418.424286, Train acc 0.588360, Test acc 0.362000, Epoch train time 1.77 min\n",
      "Epoch  7 : Train Loss 357.025238, Train acc 0.641120, Test acc 0.364000, Epoch train time 1.77 min\n",
      "Epoch  8 : Train Loss 300.169983, Train acc 0.743220, Test acc 0.386500, Epoch train time 2.00 min\n",
      "Epoch  9 : Train Loss 241.306793, Train acc 0.790960, Test acc 0.373800, Epoch train time 1.80 min\n",
      "Epoch 10 : Train Loss 188.607956, Train acc 0.855620, Test acc 0.393700, Epoch train time 1.91 min\n",
      "Epoch 11 : Train Loss 136.654572, Train acc 0.897760, Test acc 0.386100, Epoch train time 1.83 min\n",
      "Epoch 12 : Train Loss 101.832878, Train acc 0.933940, Test acc 0.385300, Epoch train time 1.95 min\n",
      "Epoch 13 : Train Loss 74.414680, Train acc 0.950140, Test acc 0.390000, Epoch train time 1.80 min\n",
      "Epoch 14 : Train Loss 52.722893, Train acc 0.974340, Test acc 0.396100, Epoch train time 1.87 min\n",
      "Epoch 15 : Train Loss 38.615421, Train acc 0.983780, Test acc 0.408600, Epoch train time 1.73 min\n",
      "Epoch 16 : Train Loss 29.644964, Train acc 0.991280, Test acc 0.414100, Epoch train time 1.86 min\n",
      "Epoch 17 : Train Loss 21.947258, Train acc 0.993280, Test acc 0.415900, Epoch train time 1.83 min\n",
      "Epoch 18 : Train Loss 17.306763, Train acc 0.996360, Test acc 0.414800, Epoch train time 1.76 min\n",
      "Epoch 19 : Train Loss 12.718595, Train acc 0.997760, Test acc 0.419000, Epoch train time 1.74 min\n",
      "Epoch 20 : Train Loss 8.604598, Train acc 0.998780, Test acc 0.421100, Epoch train time 1.93 min\n",
      "Epoch 21 : Train Loss 6.723218, Train acc 0.999180, Test acc 0.426800, Epoch train time 1.90 min\n",
      "Epoch 22 : Train Loss 5.049563, Train acc 0.999400, Test acc 0.430600, Epoch train time 1.88 min\n",
      "Epoch 23 : Train Loss 4.747934, Train acc 0.999500, Test acc 0.432200, Epoch train time 1.86 min\n",
      "Epoch 24 : Train Loss 3.931497, Train acc 0.999400, Test acc 0.427900, Epoch train time 1.68 min\n",
      "Epoch 25 : Train Loss 3.276994, Train acc 0.999560, Test acc 0.431900, Epoch train time 1.94 min\n",
      "Epoch 26 : Train Loss 2.681276, Train acc 0.999580, Test acc 0.425900, Epoch train time 1.93 min\n",
      "Epoch 27 : Train Loss 2.404474, Train acc 0.999600, Test acc 0.427900, Epoch train time 1.84 min\n",
      "Epoch 28 : Train Loss 1.985668, Train acc 0.999580, Test acc 0.429000, Epoch train time 1.89 min\n",
      "Epoch 29 : Train Loss 1.987849, Train acc 0.999600, Test acc 0.435200, Epoch train time 1.91 min\n",
      "Epoch 30 : Train Loss 1.513542, Train acc 0.999560, Test acc 0.434700, Epoch train time 1.95 min\n",
      "Epoch 31 : Train Loss 1.642871, Train acc 0.999640, Test acc 0.434000, Epoch train time 1.73 min\n",
      "Epoch 32 : Train Loss 1.407876, Train acc 0.999620, Test acc 0.435800, Epoch train time 1.68 min\n",
      "Epoch 33 : Train Loss 1.137656, Train acc 0.999520, Test acc 0.437100, Epoch train time 1.94 min\n",
      "Epoch 34 : Train Loss 1.260477, Train acc 0.999640, Test acc 0.436700, Epoch train time 2.01 min\n",
      "Epoch 35 : Train Loss 1.287967, Train acc 0.999580, Test acc 0.435600, Epoch train time 1.95 min\n",
      "Epoch 36 : Train Loss 0.981127, Train acc 0.999600, Test acc 0.440400, Epoch train time 1.80 min\n",
      "Epoch 37 : Train Loss 0.905254, Train acc 0.999620, Test acc 0.438800, Epoch train time 1.70 min\n",
      "Epoch 38 : Train Loss 0.863096, Train acc 0.999680, Test acc 0.437600, Epoch train time 1.98 min\n",
      "Epoch 39 : Train Loss 0.844777, Train acc 0.999640, Test acc 0.440400, Epoch train time 1.72 min\n",
      "Epoch 40 : Train Loss 0.876795, Train acc 0.999640, Test acc 0.436700, Epoch train time 1.90 min\n",
      "Epoch 41 : Train Loss 0.837123, Train acc 0.999640, Test acc 0.443300, Epoch train time 1.96 min\n",
      "Epoch 42 : Train Loss 0.731663, Train acc 0.999640, Test acc 0.436700, Epoch train time 1.89 min\n",
      "Epoch 43 : Train Loss 0.789411, Train acc 0.999680, Test acc 0.443100, Epoch train time 1.85 min\n",
      "Epoch 44 : Train Loss 0.713412, Train acc 0.999640, Test acc 0.440800, Epoch train time 1.96 min\n",
      "Epoch 45 : Train Loss 0.733297, Train acc 0.999700, Test acc 0.444400, Epoch train time 1.70 min\n",
      "Epoch 46 : Train Loss 0.670357, Train acc 0.999680, Test acc 0.443800, Epoch train time 1.93 min\n",
      "Epoch 47 : Train Loss 0.519362, Train acc 0.999640, Test acc 0.441600, Epoch train time 1.78 min\n",
      "Epoch 48 : Train Loss 0.564042, Train acc 0.999700, Test acc 0.443600, Epoch train time 1.88 min\n",
      "Epoch 49 : Train Loss 0.541661, Train acc 0.999680, Test acc 0.440000, Epoch train time 1.77 min\n",
      "Epoch 50 : Train Loss 0.547290, Train acc 0.999680, Test acc 0.440900, Epoch train time 1.93 min\n",
      "Epoch 51 : Train Loss 0.547457, Train acc 0.999660, Test acc 0.445000, Epoch train time 1.98 min\n",
      "Epoch 52 : Train Loss 0.533520, Train acc 0.999640, Test acc 0.444200, Epoch train time 1.85 min\n",
      "Epoch 53 : Train Loss 0.543311, Train acc 0.999680, Test acc 0.440400, Epoch train time 1.66 min\n",
      "Epoch 54 : Train Loss 0.577945, Train acc 0.999660, Test acc 0.442800, Epoch train time 1.66 min\n",
      "Epoch 55 : Train Loss 0.555882, Train acc 0.999700, Test acc 0.436700, Epoch train time 1.67 min\n",
      "Epoch 56 : Train Loss 0.494417, Train acc 0.999720, Test acc 0.439400, Epoch train time 1.68 min\n",
      "Epoch 57 : Train Loss 0.607663, Train acc 0.999700, Test acc 0.440400, Epoch train time 1.72 min\n",
      "Epoch 58 : Train Loss 0.504892, Train acc 0.999680, Test acc 0.440200, Epoch train time 1.75 min\n",
      "Epoch 59 : Train Loss 0.451653, Train acc 0.999720, Test acc 0.441700, Epoch train time 1.78 min\n",
      "Epoch 60 : Train Loss 0.483198, Train acc 0.999720, Test acc 0.442300, Epoch train time 1.77 min\n",
      "Epoch 61 : Train Loss 0.423660, Train acc 0.999760, Test acc 0.441700, Epoch train time 1.71 min\n",
      "Epoch 62 : Train Loss 0.341159, Train acc 0.999740, Test acc 0.443400, Epoch train time 1.70 min\n",
      "Epoch 63 : Train Loss 0.519176, Train acc 0.999760, Test acc 0.443300, Epoch train time 1.71 min\n",
      "Epoch 64 : Train Loss 0.382165, Train acc 0.999740, Test acc 0.443400, Epoch train time 1.70 min\n",
      "Epoch 65 : Train Loss 0.362299, Train acc 0.999760, Test acc 0.442800, Epoch train time 1.71 min\n",
      "Epoch 66 : Train Loss 0.318073, Train acc 0.999740, Test acc 0.441500, Epoch train time 1.69 min\n",
      "Epoch 67 : Train Loss 0.291527, Train acc 0.999760, Test acc 0.441900, Epoch train time 1.69 min\n",
      "Epoch 68 : Train Loss 0.330895, Train acc 0.999760, Test acc 0.445300, Epoch train time 1.68 min\n",
      "Epoch 69 : Train Loss 0.326989, Train acc 0.999760, Test acc 0.445300, Epoch train time 1.75 min\n",
      "Epoch 70 : Train Loss 0.342901, Train acc 0.999740, Test acc 0.442800, Epoch train time 1.76 min\n",
      "Epoch 71 : Train Loss 0.366899, Train acc 0.999760, Test acc 0.444200, Epoch train time 1.71 min\n",
      "Epoch 72 : Train Loss 0.312644, Train acc 0.999760, Test acc 0.443600, Epoch train time 1.79 min\n",
      "Epoch 73 : Train Loss 0.300576, Train acc 0.999760, Test acc 0.443800, Epoch train time 1.76 min\n",
      "Epoch 74 : Train Loss 0.332563, Train acc 0.999740, Test acc 0.443200, Epoch train time 1.75 min\n",
      "Epoch 75 : Train Loss 0.377748, Train acc 0.999760, Test acc 0.444200, Epoch train time 1.75 min\n",
      "Epoch 76 : Train Loss 0.317430, Train acc 0.999700, Test acc 0.444000, Epoch train time 1.78 min\n",
      "Epoch 77 : Train Loss 0.297410, Train acc 0.999740, Test acc 0.444100, Epoch train time 1.72 min\n",
      "Epoch 78 : Train Loss 0.269676, Train acc 0.999740, Test acc 0.443900, Epoch train time 1.72 min\n",
      "Epoch 79 : Train Loss 0.321338, Train acc 0.999780, Test acc 0.442400, Epoch train time 1.77 min\n"
     ]
    }
   ],
   "source": [
    "# Init\n",
    "losses = []\n",
    "test_acc = []\n",
    "train_acc = []\n",
    "# Save time\n",
    "train_time = []\n",
    "\n",
    "# Init network\n",
    "net = ResNet50(\n",
    "    channels = channels,\n",
    "    num_classes = n_classes\n",
    ").cuda()\n",
    "\n",
    "# setting hyperparameters and gettings epoch sizes\n",
    "num_epochs = 100\n",
    "\n",
    "# Data subsets\n",
    "get_slice = lambda i, size: range(i * size, (i + 1) * size)\n",
    "\n",
    "# Optimizer\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.8)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "logging.debug(\"Started training\")\n",
    "for epoch in range(num_epochs):\n",
    "    start_time = time.perf_counter()\n",
    "    # Forward -> Backprob -> Update params\n",
    "    \n",
    "    ## Train\n",
    "    cur_loss = 0\n",
    "    net.train()\n",
    "    for data in trainloader:\n",
    "        # Get data\n",
    "        x_train, y_train = data\n",
    "        \n",
    "        # Optimizer and batch\n",
    "        optimizer.zero_grad()\n",
    "        output = net(x_train.cuda())\n",
    "        \n",
    "        # compute gradients given loss\n",
    "        batch_loss = criterion(output, y_train.cuda())\n",
    "        batch_loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        cur_loss += batch_loss\n",
    "    \n",
    "    end_time = time.perf_counter()\n",
    "    train_time.append(end_time - start_time)\n",
    "    # Save losses\n",
    "    losses.append(cur_loss / batch_size) \n",
    "    \n",
    "    ### Evaluate training\n",
    "    net.eval()\n",
    "    train_preds, train_targs = [], []\n",
    "    for data in trainloader:\n",
    "        # Get data\n",
    "        x_train, y_train = data\n",
    "        output = net(x_train.cuda())\n",
    "        \n",
    "        preds = torch.max(output, 1)[1]\n",
    "        \n",
    "        train_targs += list(y_train.numpy())\n",
    "        train_preds += list(preds.data.cpu().numpy())\n",
    "    \n",
    "    ### Evaluate testing\n",
    "    test_preds, test_targs = [], []\n",
    "    for data in testloader:\n",
    "        # Get data\n",
    "        x_test, y_test = data\n",
    "        output = net(x_test.cuda())\n",
    "        preds = torch.max(output, 1)[1]\n",
    "        test_targs += list(y_test.numpy())\n",
    "        test_preds += list(preds.data.cpu().numpy())\n",
    "        \n",
    "\n",
    "    train_acc_cur = accuracy_score(train_targs, train_preds)\n",
    "    test_acc_cur = accuracy_score(test_targs, test_preds)\n",
    "    \n",
    "    train_acc.append(train_acc_cur)\n",
    "    test_acc.append(test_acc_cur)\n",
    "    \n",
    "    if epoch % 1 == 0:\n",
    "        string = \"Epoch %2i : Train Loss %f, Train acc %f, Test acc %f, Epoch train time %.2f min\" % (\n",
    "                epoch+1, losses[-1], train_acc_cur, test_acc_cur, train_time[-1]/60)\n",
    "        logging.debug(string)\n",
    "        print(string)\n",
    "\n",
    "logging.debug(f\"Total time: {sum(train_time)/(60*60)} hours\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "587ef13d",
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch = np.arange(len(train_acc))\n",
    "plt.figure()\n",
    "plt.plot(epoch, train_acc, 'r', epoch, test_acc, 'b')\n",
    "plt.legend(['Train Accucary','Testing Accuracy'])\n",
    "plt.xlabel('Updates')\n",
    "plt.ylabel('Acc')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "372c9145",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Evaluate test set\n",
    "net.eval()\n",
    "print(f'Training accuracy: {train_acc[-1]*100:.2f}%\\Testing accuracy: {test_acc[-1]*100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49b5d1c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.debug(f\"Total parameters: {sum([par.numel() for par in net.parameters()])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2db35af",
   "metadata": {},
   "outputs": [],
   "source": [
    "sum([par.numel() for par in net.parameters()])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
